{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gdal, osr\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import biomass specific libraries\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import regionprops\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chm_file = 'NEON_D17_SJER_DP3_256000_4106000_CHM.tif'\n",
    "chm_dataset = gdal.Open(chm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chm_raster = chm_dataset.GetRasterBand(1)\n",
    "chm_array = chm_raster.ReadAsArray(0,0,chm_dataset.RasterXSize,chm_dataset.RasterYSize).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(chm_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Smooth the CHM using a gaussian filter to remove spurious points\n",
    "chm_array_smooth = ndi.gaussian_filter(chm_array, 2, mode='constant', cval=0, truncate=2.0)\n",
    "chm_array_smooth[chm_array==0] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate local maximum points in the smoothed CHM\n",
    "local_maxi = peak_local_max(chm_array_smooth,indices=False, footprint=np.ones((5, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Identify all the maximum points\n",
    "markers = ndi.label(local_maxi)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a CHM mask so the segmentation will only occur on the trees\n",
    "chm_mask = chm_array_smooth\n",
    "chm_mask[chm_array_smooth != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perfrom watershed segmentation        \n",
    "labels = watershed(chm_array_smooth, markers, mask=chm_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the properties of each segment\n",
    "tree_properties = regionprops(labels, chm_array, ['Area','BoundingBox','Centroid','Orientation','MajorAxisLength','MinorAxisLength','MaxIntensity','MinIntensity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_predictors(tree, chm_array, labels):\n",
    "    indexes_of_tree = np.asarray(np.where(labels==tree.label)).T\n",
    "    tree_data = chm_array[indexes_of_tree[:,0],indexes_of_tree[:,1]]\n",
    "    full_crown = np.sum(tree_data - np.min(tree_data))\n",
    "    \n",
    "    def crown_geometric_volume_pth(pth):\n",
    "        p = np.percentile(tree_data, pth)\n",
    "        tree_data_pth = [v if v < p else p for v in tree_data]\n",
    "        crown_geometric_volume_pth = np.sum(tree_data_pth - tree.min_intensity)\n",
    "        return crown_geometric_volume_pth, p\n",
    "   \n",
    "    crown50, p50 = crown_geometric_volume_pth(50)\n",
    "    crown60, p60 = crown_geometric_volume_pth(60)\n",
    "    crown70, p70 = crown_geometric_volume_pth(70)\n",
    "    \n",
    "    return [tree.label,\n",
    "            np.float(tree.area),\n",
    "            tree.major_axis_length,\n",
    "            tree.max_intensity,\n",
    "            tree.min_intensity, \n",
    "            p50, p60, p70,\n",
    "            full_crown, crown50, crown60, crown70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors_mb = [get_predictors(tree, chm_array, labels) for tree in tree_properties]\n",
    "all_training_data_mb = np.array([x[1:] for x in predictors_mb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define the file of training data  \n",
    "training_data_file = 'SJER_Biomass_Training.csv'\n",
    "\n",
    "#Read in the training data from a CSV file\n",
    "training_data = np.genfromtxt(training_data_file,delimiter=',') \n",
    "\n",
    "#Grab the biomass (Y) from the first line\n",
    "biomass = training_data[:,0]\n",
    "\n",
    "#Grab the biomass prdeictors from the remaining lines\n",
    "biomass_predictors = training_data[:,1:12]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=30,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=2,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define paraemters for Random forest regressor\n",
    "max_depth = 30\n",
    "\n",
    "#Define regressor rules\n",
    "regr_rf = RandomForestRegressor(max_depth=max_depth, random_state=2)\n",
    "\n",
    "#Fit the biomass to regressor variables\n",
    "regr_rf.fit(biomass_predictors,biomass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stack the predictor variables for all the individual trees\n",
    "all_training_data = np.stack([area,\n",
    "                              diameter,\n",
    "                              max_tree_height,\n",
    "                              min_tree_height,\n",
    "                              percentile_50th,\n",
    "                              percentile_60th,\n",
    "                              percentile_70th,\n",
    "                              crown_geometric_volume_full,\n",
    "                              crown_geometric_volume_50th_percentile,\n",
    "                              crown_geometric_volume_60th_percentile,\n",
    "                              crown_geometric_volume_70th_percentile],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_biomass_mb = regr_rf.predict(all_training_data_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biomass_out_mb = labels\n",
    "for p, bm in zip(predictors_mb, pred_biomass_mb):\n",
    "    biomass_out_mb[biomass_out_mb==p[0]] = bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ii, (x, y) in enumerate(zip(biomass_out_mb, biomass_out)):\n",
    "    if np.sum(x==y)<len(x):\n",
    "        print(ii)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of biomass is  6978251.34548  kg\n"
     ]
    }
   ],
   "source": [
    "#Get biomass stats for plotting\n",
    "mean_biomass = np.mean(pred_biomass)\n",
    "std_biomass = np.std(pred_biomass)\n",
    "min_biomass = np.min(pred_biomass)\n",
    "sum_biomass = np.sum(pred_biomass)\n",
    "\n",
    "print('Sum of biomass is ',sum_biomass,' kg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sum of biomass is  6978251.34548  kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
